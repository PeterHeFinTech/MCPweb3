# 问题清单2（专业审阅版）

以下问题面向评审与交付质量审查，覆盖产品价值、技术架构、可靠性、安全合规、可维护性与演示可用性。请逐项确认并记录结论。

---

## 1. 目标与价值

1. 目标用户是谁？（开发者/分析师/客服/运营）
2. 是否有清晰的“用户最小价值场景（MVS）”？
3. 与现有 TRON 查询工具相比，本项目的独特价值是什么？
4. 该 MCP 服务的“不可替代性”在哪里？
5. 是否量化了节省时间/降低门槛的收益？

---

## 2. 需求覆盖与范围控制

6. 任务中“必选三项功能”是否全部可用且稳定？
7. 对“可选加分项”的优先级是否合理？
8. 是否存在“需求漂移”（实现了很多但没有必要的功能）？
9. 功能边界是否清晰，避免工具职责重叠？
10. 是否明确拒绝超出范围的请求（比如私钥管理、签名）？

---

## 3. 体系结构与分层

11. Agent Skill 与 MCP 是否彻底解耦？是否仍有暗耦合？
12. 技能文档与代码的“版本同步策略”是什么？
13. client/router/server/formatter/validator 分层是否清晰且必要？
14. 代码中是否存在过度抽象或过度设计？
15. 是否可替换底层 RPC 供应商（GetBlock → 其他）？

---

## 4. API 兼容性与协议合规

16. MCP List Tools / Call Tool 是否完全符合 SDK 规范？
17. 工具命名是否遵循服务前缀规范（tron_*）？
18. 返回结构是否稳定、可预期且有 schema？
19. 是否有“非破坏性升级”策略（新增字段不影响旧版本）？
20. 是否考虑到不同 MCP 客户端差异（Claude Desktop / others）？

---

## 5. 数据正确性与一致性

21. USDT 余额是否正确处理 6 位小数？
22. TRX 与 SUN 的换算是否统一？
23. tx status 是否正确覆盖 pending/failed/success 三态？
24. blockNumber 与确认数的关系是否清晰？
25. 是否存在“链上最终性”误导风险？

---

## 6. 错误处理与用户体验

26. 错误类型是否覆盖参数错误/网络错误/链上错误？
27. 错误返回是否具有可读性与可行动性？
28. 是否避免泄漏内部异常堆栈？
29. 超时/重试策略是否合理？
30. 失败时是否引导用户下一步动作？

---

## 7. 安全与合规

31. 是否完全不处理私钥与签名？
32. 是否存在可被注入的参数（如 call_data）？
33. 是否限制高风险操作的参数范围（如过大金额）？
34. 是否有防止钓鱼/诈骗地址提示机制？
35. 是否考虑加入 TRONSCAN 风险标签？

---

## 8. 可测试性与质量

36. 是否有集成测试覆盖真实 RPC？
37. 测试是否覆盖边界值（空地址、无效 txid、超大数）？
38. 是否有性能基准（响应时间/吞吐）？
39. 是否有 mock 层隔离外部依赖？
40. 是否定义了回归测试触发条件？

---

## 9. 可维护性与可扩展性

41. 新增一个 TRC20 Token 需要改几个文件？
42. 如果需要新增 “批量查询余额” 是否容易实现？
43. 是否有统一的参数校验入口？
44. 是否存在重复的格式化/转换逻辑？
45. 是否有清晰的开发文档与本地启动说明？

---

## 10. 演示与交付

46. 是否具备 5 分钟内可复现的演示流程？
47. 是否有演示脚本与演示数据（示例地址/txid）？
48. 是否明确安装步骤、配置项、环境变量？
49. 是否说明了 GetBlock key 的获取方式？
50. 是否提供一键运行方式（如 make/run 脚本）？

---

## 11. 风险与改进建议

51. 目前最大的技术风险是什么？
52. 目前最大的产品风险是什么？
53. 最可能被评委质疑的点是什么？
54. 若要进入生产，首先要补哪三件事？
55. MVP 之后的 2~4 周迭代路线图是什么？

---

## 12. 结论性评估（需填写）

- **整体完成度**：____/10
- **技术质量**：____/10
- **创新性**：____/10
- **可演示性**：____/10
- **推荐等级**：强烈推荐 / 推荐 / 一般 / 不推荐

---

> 备注：建议在评审会议中逐条作答，形成“问题→证据→结论→行动项”闭环。